{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fef6f4a-d635-43ce-bd42-19826cf138aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import skimage.draw\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils\n",
    "from mrcnn.visualize import display_instances\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0712e88-a7ac-456c-ab4e-3469d7a0304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# To find local version of the library\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "# Local path to trained weights file\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "639113a8-94f1-47af-af0c-0fef43fa13d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model Configuration\n",
    "class BarChartConfig(Config):\n",
    "    # Give the configuration a name\n",
    "    NAME = \"barchart\"\n",
    "    \n",
    "    #GPU_COUNT = 1\n",
    "    \n",
    "    IMAGES_PER_GPU = 1\n",
    "    \n",
    "    # Number of classes plus background\n",
    "    NUM_CLASSES = 1 + 7  # Background + (Title, Legend, X-label, Y-label, Bar, X-value, Y-value)\n",
    "    \n",
    "    # Number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 10\n",
    "    \n",
    "    # Skip detections with < 80% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1fec1be-2eaf-4348-8fe9-6fdf00fc2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarChartDataset(utils.Dataset):\n",
    "    def load_barchart(self, dataset_dir, subset):\n",
    "        \"\"\"\n",
    "        Load bar chart dataset from JSON annotations.\n",
    "        \"\"\"\n",
    "        # Define class names (same as in annotation)\n",
    "        self.add_class(\"barchart\", 1, \"title\")\n",
    "        self.add_class(\"barchart\", 2, \"legend\")\n",
    "        self.add_class(\"barchart\", 3, \"x-label\")\n",
    "        self.add_class(\"barchart\", 4, \"y-label\")\n",
    "        self.add_class(\"barchart\", 5, \"bars\")\n",
    "        self.add_class(\"barchart\", 6, \"x-ticks\")\n",
    "        self.add_class(\"barchart\", 7, \"y-ticks\")\n",
    "\n",
    "        # Validate subset type\n",
    "        assert subset in [\"training\", \"validation\"], \"Subset must be 'training' or 'validation'\"\n",
    "        json_file = os.path.join(dataset_dir, subset, f\"{subset}_data.json\")\n",
    "\n",
    "        # Load annotations\n",
    "        with open(json_file) as f:\n",
    "            annotations1 = json.load(f) \n",
    "\n",
    "        # Ensure the correct key is accessed\n",
    "        if \"_via_img_metadata\" not in annotations1:\n",
    "            raise KeyError(\"Error: '_via_img_metadata' not found in JSON file.\")\n",
    "\n",
    "        # Extract annotations\n",
    "        annotations = annotations1[\"_via_img_metadata\"]\n",
    "\n",
    "        for key, annotation in annotations.items():  # VIA stores metadata as a dictionary\n",
    "            if \"filename\" not in annotation:\n",
    "                print(f\"Skipping entry {key}: Missing 'filename' key.\")\n",
    "                continue  # Skip entries without filenames\n",
    "        \n",
    "        # Loop through each image annotation\n",
    "        for image_id, a in annotations.items():\n",
    "            image_path = os.path.join(dataset_dir, subset, a[\"filename\"])\n",
    "            height, width = self._get_image_size(image_path)\n",
    "\n",
    "            # Add image and annotations to dataset\n",
    "            self.add_image(\n",
    "                source=\"barchart\",\n",
    "                image_id=image_id,\n",
    "                path=image_path,\n",
    "                width=width,\n",
    "                height=height,\n",
    "                annotations=a[\"regions\"]\n",
    "            )\n",
    "\n",
    "    def _get_image_size(self, image_path):\n",
    "        \"\"\"Helper function to get image dimensions\"\"\"\n",
    "        image = skimage.io.imread(image_path)\n",
    "        return image.shape[:2]\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"\n",
    "        Generate instance masks for an image.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        annotations = info[\"annotations\"]\n",
    "        num_instances = len(annotations)\n",
    "\n",
    "        # Create an empty mask array\n",
    "        mask = np.zeros([info[\"height\"], info[\"width\"], num_instances], dtype=np.uint8)\n",
    "        class_ids = []\n",
    "\n",
    "        # Iterate through annotations\n",
    "        for i, annotation in enumerate(annotations):\n",
    "            x = annotation[\"shape_attributes\"][\"x\"]\n",
    "            y = annotation[\"shape_attributes\"][\"y\"]\n",
    "            w = annotation[\"shape_attributes\"][\"width\"]\n",
    "            h = annotation[\"shape_attributes\"][\"height\"]\n",
    "\n",
    "            # Draw filled rectangle for each annotation\n",
    "            mask[y:y+h, x:x+w, i] = 1\n",
    "\n",
    "            # Assign class ID\n",
    "            class_name = annotation[\"region_attributes\"][\"class\"]\n",
    "            class_id = self.class_names.index(class_name) if class_name in self.class_names else -1\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "        return mask.astype(np.bool_), np.array(class_ids, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eb4aab-b4ac-46fb-8cd8-5b5b0ea98b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:442: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:58: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3543: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3386: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1768: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Downloads\\New project\\Mask_RCNN\\mrcnn\\model.py:554: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Downloads\\New project\\Mask_RCNN\\mrcnn\\utils.py:202: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\Downloads\\New project\\Mask_RCNN\\mrcnn\\model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "Loading COCO weights...\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: C:\\Users\\owner\\Downloads\\New project\\Mask_RCNN\\logs\\barchart20250205T0818\\mask_rcnn_barchart_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:625: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\callbacks.py:705: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\owner\\anaconda3\\envs\\MLINSIGHT\\lib\\site-packages\\keras\\callbacks.py:708: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def train_model(model):\n",
    "    \"\"\"\n",
    "    Train the Mask R-CNN model on the Bar Chart dataset and track training/validation losses.\n",
    "    \"\"\"\n",
    "    dataset_dir = \"C:\\\\Users\\\\owner\\\\Downloads\\\\New project\\\\Mask_RCNN\\\\Dataset\"\n",
    "\n",
    "    # Load training dataset\n",
    "    dataset_train = BarChartDataset()\n",
    "    dataset_train.load_barchart(dataset_dir, \"training\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Load validation dataset\n",
    "    dataset_val = BarChartDataset()\n",
    "    dataset_val.load_barchart(dataset_dir, \"validation\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    print(\"Training network heads\")\n",
    "\n",
    "    # To track training and validation losses\n",
    "    class MetricsHistory:\n",
    "        def __init__(self):\n",
    "            self.train_losses = []\n",
    "            self.val_losses = []\n",
    "\n",
    "        def on_epoch_end(self, epoch, logs):\n",
    "            # Append metrics from the logs to track loss\n",
    "            self.train_losses.append(logs[\"loss\"])\n",
    "            self.val_losses.append(logs[\"val_loss\"])\n",
    "\n",
    "    # Initialize metrics history tracker\n",
    "    metrics_history = MetricsHistory()\n",
    "\n",
    "    # Define the custom callback to record loss metrics\n",
    "    class CustomCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs=None):\n",
    "            if logs:\n",
    "                metrics_history.on_epoch_end(epoch, logs)\n",
    "\n",
    "    # Train the model\n",
    "    model.train(\n",
    "        train_dataset=dataset_train,\n",
    "        val_dataset=dataset_val,\n",
    "        learning_rate=config.LEARNING_RATE,\n",
    "        epochs=10,\n",
    "        layers=\"heads\",\n",
    "        custom_callbacks=[CustomCallback()]  # Include custom metrics callback\n",
    "    )\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    epochs = range(1, len(metrics_history.train_losses) + 1)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, metrics_history.train_losses, 'r', label=\"Training Loss\")\n",
    "    plt.plot(epochs, metrics_history.val_losses, 'b', label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Create configuration and model\n",
    "config = BarChartConfig()\n",
    "MODEL_DIR = \"C:\\\\Users\\\\owner\\\\Downloads\\\\New project\\\\Mask_RCNN\\\\logs\"\n",
    "COCO_MODEL_PATH = \"C:\\\\Users\\\\owner\\\\Downloads\\\\New project\\\\Mask_RCNN\\\\mask_rcnn_coco.h5\"\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=MODEL_DIR)\n",
    "\n",
    "# Ensure COCO pre-trained weights exist\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    print(f\"Downloading COCO weights to {COCO_MODEL_PATH}...\")\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)\n",
    "\n",
    "# Load COCO weights (excluding incompatible layers)\n",
    "print(\"Loading COCO weights...\")\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \n",
    "                            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Start training\n",
    "train_model(model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
